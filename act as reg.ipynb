{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     33,
     60,
     68
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "# %load_ext jupyternotify\n",
    "\n",
    "# read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     17,
     20,
     25,
     96
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers and the needed functions\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "def d_tf_iden(x): return tf.ones_like(x)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg='A',act=tf_iden,d_act=d_tf_iden):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.current_case   = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "    \n",
    "    def feedforward(self,input,stride=1,padding='SAME',training_phase=True,std_value=0.0005):\n",
    "        self.input  = input\n",
    "        \n",
    "        if self.current_case == 'B':\n",
    "            def training_fn():  return tf.nn.dropout(tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding),0.8)\n",
    "            def  testing_fn():  return tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "            self.layer  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "            \n",
    "        elif self.current_case == 'E':\n",
    "            def training_fn():  return tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "            def  testing_fn():\n",
    "                sampled_weight = tf.squeeze(tf.distributions.Normal(loc=self.w, scale=std_value).sample(1))\n",
    "                return tf.nn.conv2d(input,sampled_weight,strides=[1,stride,stride,1],padding=padding) \n",
    "            self.layer  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "            \n",
    "        else: self.layer = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,std_value,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        if self.current_case == 'D' or self.current_case == 'E': grad = tf.squeeze(tf.distributions.Normal(loc=grad, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        \n",
    "        if self.current_case == 'C' or self.current_case == 'D' or self.current_case == 'E': adam_middle = tf.squeeze(tf.distributions.Normal(loc=adam_middle, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "\n",
    "class RELU_as_Reg():\n",
    "    \n",
    "    def __init__(self,batch,width,channel,regularizer):\n",
    "        self.w = tf.Variable(tf.random_uniform([batch,width,width,channel],minval=0.0,maxval=1.0))\n",
    "        self.regularizer = regularizer\n",
    "        self.lamda = 0.00001\n",
    "    \n",
    "    def feedforward(self,input):\n",
    "        self.input  = input\n",
    "        self.layerA = self.w * input\n",
    "        return self.layerA\n",
    "    \n",
    "    def backprop(self,gradient):\n",
    "        grad = gradient * self.input\n",
    "        gradient_p = self.w * gradient\n",
    "        \n",
    "        # add reg here\n",
    "        if self.regularizer == 'A': grad = grad + self.lamda * tf.sign(self.w)\n",
    "        if self.regularizer == 'B': grad = grad + self.lamda * 2.0 * self.w\n",
    "        if self.regularizer == 'C': grad = grad + self.lamda * (1.0/tf.sqrt(tf.square(self.w)+ 1e-5)) * self.w\n",
    "        if self.regularizer == 'D': grad = grad + self.lamda * -(2*self.w)/(1 + self.w**2)\n",
    "        if self.regularizer == 'E': grad = grad + self.lamda * -(1-tf.tanh(self.w) ** 2)\n",
    "        if self.regularizer == 'F': grad = grad + self.lamda * -(1-tf.tanh(self.w** 2) ** 2) * 2.0 * self.w \n",
    "        if self.regularizer == 'G': grad = grad + self.lamda * -(1-tf.tanh(tf.abs(self.w)) ** 2) * tf.sign(self.w)\n",
    "        if self.regularizer == 'H': grad = grad + self.lamda * -(1-tf.tanh(tf.abs(self.w)** 2) ** 2) * 2.0 * tf.abs(self.w) *  tf.sign(self.w)\n",
    "        if self.regularizer == 'I': grad = grad + self.lamda * tf.cos(self.w)\n",
    "        if self.regularizer == 'J': grad = grad + self.lamda * tf.sign(tf.sin(self.w)) * tf.cos(self.w)\n",
    "        if self.regularizer == 'K': grad = grad + self.lamda * (2)/(self.w + 1e-5)\n",
    "        if self.regularizer == 'L': grad = grad + self.lamda * (tf.log(self.w**2) + 2.0)\n",
    "        # add reg here\n",
    "\n",
    "        gradient_temp = tf.clip_by_value(self.w - learning_rate * grad,clip_value_min=0.0,clip_value_max=1.0)\n",
    "        update_w = []\n",
    "        update_w.append(self.w.assign(gradient_temp))\n",
    "        \n",
    "        return gradient_p,update_w\n",
    "\n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "num_eps   = 2; num_epoch = 50; learning_rate = 0.0008; batch_size = 20; \n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-9; \n",
    "print_iter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ================================================\n",
      "                    Starting Episode: 0 for B\n",
      "        ================================================\n",
      "\n",
      "Current : 0\t Train Acc : 0.144\t Test Acc : 0.168\t STD : 0.0005\t0005\n",
      "Current : 2\t Train Acc : 0.166\t Test Acc : 0.176\t STD : 0.0005\t\n",
      "Current : 4\t Train Acc : 0.182\t Test Acc : 0.185\t STD : 0.0005\t\n",
      "Current : 6\t Train Acc : 0.198\t Test Acc : 0.192\t STD : 0.0005\t\n",
      "Current : 8\t Train Acc : 0.203\t Test Acc : 0.205\t STD : 0.0005\t\n",
      "Current : 10\t Train Acc : 0.209\t Test Acc : 0.216\t STD : 0.0005\t\n",
      "Current : 12\t Train Acc : 0.221\t Test Acc : 0.233\t STD : 0.0005\t\n",
      "Current : 14\t Train Acc : 0.237\t Test Acc : 0.243\t STD : 0.0005\t\n",
      "Current : 16\t Train Acc : 0.253\t Test Acc : 0.25\t STD : 0.0005\t5\n",
      "Current : 18\t Train Acc : 0.258\t Test Acc : 0.253\t STD : 0.0005\t\n",
      " Current Iter : 19/50\tbatch : 1340/5000\tacc : 0.35\tstd  : 0.0005\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3a183b9722e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mcurrent_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0msess_results\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient_update\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_std_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n\u001b[1;32m     95\u001b[0m                                  \u001b[0;34m'\\tbatch : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no batch\n",
    "current_batch_norm_type = 'act_as_reg'\n",
    "all_the_exp = ['B','C','D','E']\n",
    "\n",
    "for letter in all_the_exp:\n",
    "    current_exp_name = letter\n",
    "    sess = tf.InteractiveSession()\n",
    "    current_exp_train_accuracy = np.zeros((num_eps,num_epoch))\n",
    "    current_exp_test_accuracy  = np.zeros((num_eps,num_epoch))\n",
    "    MAX_STD_VALUE = 0.0005\n",
    "\n",
    "    for episode in range(num_eps):\n",
    "        sys.stdout.write(\"\"\"\n",
    "        ================================================\n",
    "                    Starting Episode: \"\"\" + str(episode) + \" for \" + str(letter) + \"\"\"\n",
    "        ================================================\\n\n",
    "        \"\"\");sys.stdout.flush();\n",
    "\n",
    "        # create layers\n",
    "        l1 = CNN(3,3, 16,which_reg='A'); \n",
    "        l1_act = RELU_as_Reg(batch_size,48,16,regularizer=letter)\n",
    "        l2 = CNN(3,16,16,which_reg='A'); \n",
    "        l2_act = RELU_as_Reg(batch_size,24,16,regularizer=letter)\n",
    "        l3 = CNN(3,16,16,which_reg='A'); \n",
    "        l3_act = RELU_as_Reg(batch_size,12,16,regularizer=letter)\n",
    "        l4 = CNN(3,16,16,which_reg='A'); \n",
    "        l4_act = RELU_as_Reg(batch_size,6 ,16,regularizer=letter)\n",
    "        l5 = CNN(3,16,16,which_reg='A'); \n",
    "        l5_act = RELU_as_Reg(batch_size,6 ,16,regularizer=letter)\n",
    "        l6 = CNN(3,16,10,which_reg='A'); \n",
    "\n",
    "        # 2. graph \n",
    "        x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "        y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "        is_train  = tf.placeholder_with_default(True,())\n",
    "        std_value = tf.placeholder(tf.float32)\n",
    "\n",
    "        layer1, layer1a = l1. feedforward(x,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer1ar = l1_act.feedforward(layer1a)\n",
    "        layer2, layer2a = l2. feedforward(layer1ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer2ar = l2_act.feedforward(layer2a)\n",
    "        layer3, layer3a = l3. feedforward(layer2ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer3ar = l3_act.feedforward(layer3a)\n",
    "        layer4, layer4a = l4. feedforward(layer3ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer4ar = l4_act.feedforward(layer4a)\n",
    "        layer5, layer5a = l5. feedforward(layer4ar,training_phase=is_train,std_value=std_value)\n",
    "        layer5ar = l5_act.feedforward(layer5a)\n",
    "        layer6, layer6a = l6. feedforward(layer5ar,training_phase=is_train,std_value=std_value)\n",
    "        \n",
    "        final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "        final_softmax = tf_softmax(final_layer)\n",
    "        cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "        correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "        accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "        grad6p,grad6w,grad6_up = l6.backprop(gradient,std_value=std_value)\n",
    "        \n",
    "        grad5ap,grad5ap_up     = l5_act.backprop(grad6p)\n",
    "        grad5p,grad5w,grad5_up = l5.backprop(grad5ap,std_value=std_value)\n",
    "        \n",
    "        grad4ap,grad4ap_up     = l4_act.backprop(grad5p)\n",
    "        grad4p,grad4w,grad4_up = l4.backprop(grad4ap,stride=2,std_value=std_value)\n",
    "        \n",
    "        grad3ap,grad3ap_up     = l3_act.backprop(grad4p)\n",
    "        grad3p,grad3w,grad3_up = l3.backprop(grad3ap,stride=2,std_value=std_value)\n",
    "\n",
    "        grad2ap,grad2ap_up     = l2_act.backprop(grad3p)\n",
    "        grad2p,grad2w,grad2_up = l2.backprop(grad2ap,stride=2,std_value=std_value)\n",
    "\n",
    "        grad1ap,grad1ap_up     = l1_act.backprop(grad2p)\n",
    "        grad1p,grad1w,grad1_up = l1.backprop(grad1ap,stride=2,std_value=std_value)\n",
    "\n",
    "        gradient_update = grad6_up + \\\n",
    "                          grad5ap_up + grad5_up + \\\n",
    "                          grad4ap_up + grad4_up + \\\n",
    "                          grad3ap_up + grad3_up + \\\n",
    "                          grad2ap_up + grad2_up + \\\n",
    "                          grad1ap_up + grad1_up \n",
    "\n",
    "        # train\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "\n",
    "        for iter in range(num_epoch):\n",
    "\n",
    "            current_std_value = MAX_STD_VALUE\n",
    "\n",
    "            # Training Accuracy    \n",
    "            for current_batch_index in range(0,len(train_images),batch_size):\n",
    "                current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label,std_value:current_std_value})\n",
    "                sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                                 '\\tbatch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                                 '\\tacc : ' + str(sess_results[0]) +\n",
    "                                 '\\tstd  : ' + str(current_std_value) +\n",
    "                                 '\\r')\n",
    "                sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "\n",
    "            # Test Accuracy    \n",
    "            for current_batch_index in range(0,len(test_images), batch_size):\n",
    "                current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False,std_value:current_std_value})\n",
    "                sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                                 '\\tbatch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                                 '\\tacc : ' + str(sess_results[0]) + \n",
    "                                 '\\tstd  : ' + str(current_std_value) +\n",
    "                                 '\\r')\n",
    "                sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "\n",
    "            # ======================== print reset ========================\n",
    "            train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "            test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "            if iter%print_iter == 0 or iter==num_epoch-1 :\n",
    "                sys.stdout.write(\"Current : \"+ str(iter) + \"\\t\" +\n",
    "                      \" Train Acc : \" + str(np.around(avg_acc_train/(len(train_images)/batch_size),3)) + \"\\t\" +\n",
    "                      \" Test Acc : \"  + str(np.around(avg_acc_test/(len(test_images)/batch_size),3)) +  \"\\t\" +\n",
    "                      \" STD : \"  + str(current_std_value) + \n",
    "                      \"\\t\\n\")\n",
    "                sys.stdout.flush();\n",
    "            avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "            # ======================== print reset ========================\n",
    "            \n",
    "        # save the file\n",
    "        current_exp_train_accuracy[episode,:] = train_acc\n",
    "        current_exp_test_accuracy [episode,:] = test_acc\n",
    "        send_notification_email(letter,episode)\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "    # close the session and save\n",
    "    sess.close()\n",
    "    \n",
    "    # save to the file\n",
    "    np.save(str(current_batch_norm_type)+'/'+str(letter)+'/train.npy', current_exp_train_accuracy)\n",
    "    np.save(str(current_batch_norm_type)+'/'+str(letter)+'/test.npy', current_exp_test_accuracy)\n",
    "    print(current_exp_train_accuracy.shape,current_exp_train_accuracy.mean())\n",
    "    print(current_exp_test_accuracy.shape,current_exp_test_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
